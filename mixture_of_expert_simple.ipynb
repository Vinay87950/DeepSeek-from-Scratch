{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemnting a basic how mixture of expert usually works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.set_device(2)  # use GPU 2\n",
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____Python, Pytorch, Cuda info____\n",
      "__Python VERSION: 3.10.12 (main, Jan 17 2025, 14:35:34) [GCC 11.4.0]\n",
      "__pyTorch VERSION: 2.6.0+cu124\n",
      "__CUDA RUNTIME API VERSION\n",
      "__CUDNN VERSION: 90100\n",
      "_____nvidia-smi GPU details____\n",
      "index, name, driver_version, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "0, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 29739 MiB, 10704 MiB\n",
      "1, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 40127 MiB, 316 MiB\n",
      "2, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 1633 MiB, 38810 MiB\n",
      "3, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 3897 MiB, 36546 MiB\n",
      "4, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 4987 MiB, 35456 MiB\n",
      "5, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 4987 MiB, 35456 MiB\n",
      "6, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 4731 MiB, 35712 MiB\n",
      "7, NVIDIA A100-PCIE-40GB, 570.133.20, 40960 MiB, 30951 MiB, 9492 MiB\n",
      "_____Device assignments____\n",
      "Number CUDA Devices: 8\n",
      "Current cuda device:  2  **May not correspond to nvidia-smi ID above, check visibility parameter\n",
      "Device name:  NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from subprocess import call\n",
    "print('_____Python, Pytorch, Cuda info____')\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA RUNTIME API VERSION')\n",
    "#os.system('nvcc --version')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('_____nvidia-smi GPU details____')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('_____Device assignments____')\n",
    "print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "print ('Current cuda device: ', torch.cuda.current_device(), ' **May not correspond to nvidia-smi ID above, check visibility parameter')\n",
    "print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing MOE for just a simple neural network\n",
    "\n",
    "# Define Expert \n",
    "'''Expert as the name specifies, it is the expert model and produce the output of it's weights in the form of probabilies '''\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        return torch.softmax(self.layer2(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Gating network, what they do is simple predict weight for each expert, determining their contribution to the expert'''\n",
    "\n",
    "class Gating(nn.Module):\n",
    "    def __init__(self, input_dim, num_expert, dropout=0.1):\n",
    "        super(Gating, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.layer2 = nn.Linear(128, 256)\n",
    "        self.relu1 = nn.GELU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.layer3 = nn.Linear(256, 512)\n",
    "        self.relu2 = nn.GELU()\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.layer4 = nn.Linear(512, num_expert)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        return torch.softmax(self.layer4(x), dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining MOE \n",
    "'''so it contains multiple trained expert using gating mechnanism, so by adjusting weights and aggregating output, it generates a unified prediction'''\n",
    "\n",
    "class Mixture_of_Expert(nn.Module):\n",
    "    def __init__(self, trained_expert):\n",
    "        super(Mixture_of_Expert, self).__init__()\n",
    "        self.expert = nn.ModuleList(trained_expert)\n",
    "\n",
    "        #freeze the expert when MoE is training so that we don't wanna change our prediction\n",
    "        for experts in self.expert:\n",
    "            for param in experts.parameters():\n",
    "                param.requires_grad=False\n",
    "\n",
    "        num_expert = len(trained_expert)\n",
    "\n",
    "        # let's say all expert have the same input dim\n",
    "        input_dim = trained_expert[0].layer1.in_features\n",
    "        self.gating = Gating(input_dim, num_expert)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = self.gating(x)\n",
    "        outputs = torch.stack([experts(x) for experts in self.expert], dim=2) # expert output\n",
    "\n",
    "        # adjust weights output tensor\n",
    "        weights = weights.unsqueeze(1).expand_as(outputs)\n",
    "\n",
    "        # multiply and sum\n",
    "        return torch.sum(outputs*weights, dim=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoE train: torch.Size([2000, 4]), Test: torch.Size([500, 4])\n",
      "Experts: torch.Size([1639, 4]), torch.Size([1639, 4]), torch.Size([1639, 4])\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "num_samples = 5000\n",
    "input_dim = 4\n",
    "\n",
    "# Generate balanced labels and features\n",
    "labels_per_class = num_samples // 3\n",
    "remainder = num_samples % 3\n",
    "y_data = torch.cat([\n",
    "    torch.full((labels_per_class,), 0),\n",
    "    torch.full((labels_per_class,), 1), \n",
    "    torch.full((labels_per_class + remainder,), 2)\n",
    "]).long()\n",
    "x_data = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# Add class-specific bias\n",
    "bias_map = {0: (0, 1.0), 1: (1, -1.0), 2: (0, -1.0)}  # (feature_idx, bias_value)\n",
    "for label, (feat_idx, bias) in bias_map.items():\n",
    "    mask = y_data == label\n",
    "    x_data[mask, feat_idx] += bias\n",
    "\n",
    "# Shuffle data\n",
    "perm = torch.randperm(num_samples)\n",
    "x_data, y_data = x_data[perm], y_data[perm]\n",
    "\n",
    "# Split data: 40% experts, 32% MoE train, 8% test\n",
    "split1, split2 = num_samples // 2, int(num_samples * 0.9)\n",
    "\n",
    "# Expert data (each expert sees 2 out of 3 classes)\n",
    "expert_masks = [\n",
    "    (y_data[:split1] == 0) | (y_data[:split1] == 1),  # Expert 1: classes 0,1\n",
    "    (y_data[:split1] == 1) | (y_data[:split1] == 2),  # Expert 2: classes 1,2  \n",
    "    (y_data[:split1] == 0) | (y_data[:split1] == 2),  # Expert 3: classes 0,2\n",
    "]\n",
    "\n",
    "expert_data = []\n",
    "min_samples = min(mask.sum() for mask in expert_masks)\n",
    "for i, mask in enumerate(expert_masks):\n",
    "    expert_data.append((\n",
    "        x_data[:split1][mask][:min_samples],\n",
    "        y_data[:split1][mask][:min_samples]\n",
    "    ))\n",
    "\n",
    "# MoE training and test data\n",
    "x_train_moe, y_train_moe = x_data[split1:split2], y_data[split1:split2]\n",
    "x_test, y_test = x_data[split2:], y_data[split2:]\n",
    "\n",
    "# Unpack expert data\n",
    "(x_expert1, y_expert1), (x_expert2, y_expert2), (x_expert3, y_expert3) = expert_data\n",
    "\n",
    "print(f\"MoE train: {x_train_moe.shape}, Test: {x_test.shape}\")\n",
    "print(f\"Experts: {x_expert1.shape}, {x_expert2.shape}, {x_expert3.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Experts:   6%|▌         | 29/500 [00:00<00:01, 283.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Expert 1 Loss: 1.0991\n",
      "Epoch 0, Expert 2 Loss: 1.1377\n",
      "Epoch 0, Expert 3 Loss: 1.1105\n",
      "Epoch 50, Expert 1 Loss: 0.9584\n",
      "Epoch 50, Expert 2 Loss: 0.9745\n",
      "Epoch 50, Expert 3 Loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Experts:  30%|██▉       | 149/500 [00:00<00:01, 291.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Expert 1 Loss: 0.8680\n",
      "Epoch 100, Expert 2 Loss: 0.8770\n",
      "Epoch 100, Expert 3 Loss: 0.8364\n",
      "Epoch 150, Expert 1 Loss: 0.8198\n",
      "Epoch 150, Expert 2 Loss: 0.8281\n",
      "Epoch 150, Expert 3 Loss: 0.7658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Experts:  48%|████▊     | 239/500 [00:00<00:00, 289.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Expert 1 Loss: 0.7980\n",
      "Epoch 200, Expert 2 Loss: 0.8070\n",
      "Epoch 200, Expert 3 Loss: 0.7357\n",
      "Epoch 250, Expert 1 Loss: 0.7879\n",
      "Epoch 250, Expert 2 Loss: 0.7971\n",
      "Epoch 250, Expert 3 Loss: 0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Experts:  65%|██████▌   | 326/500 [00:01<00:00, 275.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, Expert 1 Loss: 0.7824\n",
      "Epoch 300, Expert 2 Loss: 0.7916\n",
      "Epoch 300, Expert 3 Loss: 0.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Experts:  76%|███████▌  | 381/500 [00:01<00:00, 259.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, Expert 1 Loss: 0.7789\n",
      "Epoch 350, Expert 2 Loss: 0.7880\n",
      "Epoch 350, Expert 3 Loss: 0.7102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Experts:  87%|████████▋ | 434/500 [00:01<00:00, 253.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, Expert 1 Loss: 0.7765\n",
      "Epoch 400, Expert 2 Loss: 0.7855\n",
      "Epoch 400, Expert 3 Loss: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Experts: 100%|██████████| 500/500 [00:01<00:00, 270.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, Expert 1 Loss: 0.7750\n",
      "Epoch 450, Expert 2 Loss: 0.7839\n",
      "Epoch 450, Expert 3 Loss: 0.7049\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "output_dim = 3\n",
    "hidden_dim = 32\n",
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize experts and optimizers\n",
    "experts = [Expert(input_dim, hidden_dim, output_dim) for _ in range(3)]\n",
    "optimizers = [optim.Adam(expert.parameters(), lr=learning_rate) for expert in experts]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Expert training data (assuming from previous code)\n",
    "expert_datasets = [(x_expert1, y_expert1), (x_expert2, y_expert2), (x_expert3, y_expert3)]\n",
    "\n",
    "# Single training loop for all experts\n",
    "for epoch in tqdm(range(epochs), desc=\"Training Experts\"):\n",
    "    for i, (expert, optimizer, (x_data, y_data)) in enumerate(zip(experts, optimizers, expert_datasets)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = expert(x_data)\n",
    "        loss = criterion(outputs, y_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Optional: print loss every 50 epochs\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Expert {i+1} Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MoE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:   1%|          | 6/500 [00:00<00:08, 58.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MoE Loss: 0.9517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  12%|█▏        | 60/500 [00:00<00:06, 70.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, MoE Loss: 0.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  23%|██▎       | 115/500 [00:01<00:05, 73.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, MoE Loss: 0.8706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  33%|███▎      | 163/500 [00:02<00:04, 70.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, MoE Loss: 0.8633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  42%|████▏     | 211/500 [00:02<00:04, 70.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, MoE Loss: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  52%|█████▏    | 258/500 [00:03<00:03, 69.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250, MoE Loss: 0.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  63%|██████▎   | 314/500 [00:04<00:02, 71.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, MoE Loss: 0.8568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  72%|███████▏  | 362/500 [00:05<00:01, 70.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, MoE Loss: 0.8559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  82%|████████▏ | 410/500 [00:05<00:01, 70.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, MoE Loss: 0.8541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE:  92%|█████████▏| 460/500 [00:06<00:00, 77.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, MoE Loss: 0.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MoE: 100%|██████████| 500/500 [00:06<00:00, 71.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoE training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "moe_model = Mixture_of_Expert(experts)  # Pass the trained experts list\n",
    "optimizer_moe = optim.Adam(moe_model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"Training MoE model...\")\n",
    "for epoch in tqdm(range(epochs), desc=\"Training MoE\"):\n",
    "    optimizer_moe.zero_grad()\n",
    "    outputs_moe = moe_model(x_train_moe)\n",
    "    loss_moe = criterion(outputs_moe, y_train_moe)\n",
    "    loss_moe.backward()\n",
    "    optimizer_moe.step()\n",
    "    \n",
    "    # Optional: print loss every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, MoE Loss: {loss_moe.item():.4f}\")\n",
    "\n",
    "print(\"MoE training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert 1 Accuracy: 0.4720\n",
      "Expert 2 Accuracy: 0.4920\n",
      "Expert 3 Accuracy: 0.5740\n",
      "Mixture_of_Expert Accuracy: 0.6420\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, x, y):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate all models\n",
    "models = {'Expert 1': experts[0], 'Expert 2': experts[1], 'Expert 3': experts[2], 'Mixture_of_Expert': moe_model}\n",
    "results = {name: evaluate(model, x_test, y_test) for name, model in models.items()}\n",
    "\n",
    "# Print results\n",
    "for name, accuracy in results.items():\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
